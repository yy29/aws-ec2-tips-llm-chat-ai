# LLM Evaluation

### Evaluation Tools
- [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness)
- [lighteval](https://github.com/huggingface/lighteval)

### Evaluation Benchmarks
- Open LLM Leaderboard
- HumanEval
- HellaSwag
- MMLU
- TruthfulQA
- BigCodeBench
- HELM
