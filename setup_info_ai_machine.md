# AI Machine Specs and Info

### Personal GPU Specs
- NVIDIA RTX PRO 6000 Blackwell Workstation Edition (96GB) ([info](https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/))
- NVIDIA RTX PRO 5000 Blackwell (48GB) ([info](https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/))
- NVIDIA RTX PRO 4500 Blackwell (32GB) ([info](https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/))
- NVIDIA RTX PRO 4000 Blackwell (24GB) ([info](https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/))
- NVIDIA RTX PRO 2000 Blackwell (16GB) ([info](https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/))
- NVIDIA RTX 5090 (32GB) ([info](https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/))
- NVIDIA RTX 5080 (16GB) ([info](https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/))
- NVIDIA RTX 5070 Ti (16GB) ([info](https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/))
- NVIDIA RTX 5060 Ti (16GB) ([info](https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/))

### Personal AI Machine Specs
- NVIDIA DGX Station (288GB) ([info](https://www.nvidia.com/en-us/products/workstations/dgx-station/))
- NVIDIA DGX Spark (128GB) ([info](https://www.nvidia.com/en-us/products/workstations/dgx-spark/))

### Enterprise AI Machine Specs
- NVIDIA DGX GB300 System ([info](https://www.nvidia.com/en-us/data-center/dgx-gb300/?ncid=no-ncid))
- NVIDIA DGX GB200 System ([info](https://www.nvidia.com/en-us/data-center/dgx-gb200/?ncid=no-ncid))
- NVIDIA DGX B300 System (2300GB) ([info](https://www.nvidia.com/en-us/data-center/dgx-b300/?ncid=no-ncid))
- NVIDIA DGX B200 System (1440GB) ([info](https://www.nvidia.com/en-us/data-center/dgx-b200/?ncid=no-ncid))
- NVIDIA DGX H200 System (1128GB) ([info](https://www.nvidia.com/en-us/data-center/dgx-h200/?ncid=no-ncid))

### Cloud AI Machine Specs
- AWS EC2 p6: NVIDIA B200 GPU (180GB)
- AWS EC2 p5: NVIDIA H100/H200 GPU (80GB/141GB)
- AWS EC2 p4: NVIDIA A100 GPU (40GB/80GB)
- AWS EC2 g6e: NVIDIA L40S GPU (48GB)
- AWS EC2 g6: NVIDIA L4 GPU (24GB)
- AWS EC2 g5: NVIDIA A10G GPU (24GB)
- AWS EC2 g4dn: NVIDIA T4 GPU (16GB)
- Google Cloud Compute Engine A4X: NVIDIA B200 GPU (180GB)
- Google Cloud Compute Engine A4: NVIDIA B200 GPU (180GB)
- Google Cloud Compute Engine A3: NVIDIA H100/H200 GPU (80GB/141GB)
- Google Cloud Compute Engine A2: NVIDIA A100 GPU (40GB/80GB)
- Google Cloud Compute Engine G4: NVIDIA RTX PRO 6000 Blackwell (96GB)
- Google Cloud Compute Engine G2: NVIDIA L4 GPU (24GB)
- CoreWeave NVIDIA GB300 NVL72 (279GB) ([info](https://www.coreweave.com/products/nvidia-blackwell))
- CoreWeave NVIDIA GB200 NVL72 (186GB) ([info](https://www.coreweave.com/products/nvidia-blackwell))
- CoreWeave NVIDIA B200 (180GB) ([info](https://www.coreweave.com/products/nvidia-blackwell))
- CoreWeave NVIDIA HGX H200 (141GB) ([info](https://www.coreweave.com/products/hgx-h100-h200)
- CoreWeave NVIDIA HGX H100 (80GB) ([info](https://www.coreweave.com/products/hgx-h100-h200)
- CoreWeave NVIDIA GH200 (96GB) ([info](https://www.coreweave.com/products/hgx-h100-h200)
- CoreWeave NVIDIA A100 (80GB) ([info](https://www.coreweave.com/products/gpu-compute))
- CoreWeave NVIDIA RTX PRO 6000 Blackwell Server Edition (96GB) ([info](https://www.coreweave.com/products/gpu-compute))
- CoreWeave NVIDIA L40S (48GB) ([info](https://www.coreweave.com/products/gpu-compute))
- CoreWeave NVIDIA L40 (48GB) ([info](https://www.coreweave.com/products/gpu-compute))
- NVIDIA DGX Cloud
- Google Colab

### Cloud CPU Machine Specs
- AWS EC2 m7a, m8i, m8g: General Purpose CPU
- AWS EC2 r7a, r8i, r8g: Memory Optimized CPU
- AWS EC2 c7a, c7i, c8g: Compute Optimized CPU
- AWS EC2 i7i, i8g: Storage Optimized CPU
- AWS EC2 t3, t4g: Tiny CPU
