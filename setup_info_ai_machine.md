# AI Machine Specs and Info

### Personal GPU Specs
- NVIDIA RTX PRO 6000 Blackwell Workstation Edition (96GB) ([info](https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/))
- NVIDIA RTX PRO 5000 Blackwell (48GB) ([info](https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/))
- NVIDIA RTX PRO 4500 Blackwell (32GB) ([info](https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/))
- NVIDIA RTX PRO 4000 Blackwell (24GB) ([info](https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/))
- NVIDIA RTX PRO 2000 Blackwell (16GB) ([info](https://www.nvidia.com/en-us/products/workstations/professional-desktop-gpus/))
- NVIDIA RTX 5090 (32GB) ([info](https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/))
- NVIDIA RTX 5080 (16GB) ([info](https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/))
- NVIDIA RTX 5070 Ti (16GB) ([info](https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/))
- NVIDIA RTX 5060 Ti (16GB) ([info](https://www.nvidia.com/en-us/geforce/graphics-cards/50-series/))

### Personal AI Machine Specs
- NVIDIA DGX Station (288GB) ([info](https://www.nvidia.com/en-us/products/workstations/dgx-station/))
- NVIDIA DGX Spark (128GB) ([info](https://www.nvidia.com/en-us/products/workstations/dgx-spark/))

### Enterprise AI Machine Specs
- NVIDIA DGX GB300 System ([info](https://www.nvidia.com/en-us/data-center/dgx-gb300/?ncid=no-ncid))
- NVIDIA DGX GB200 System ([info](https://www.nvidia.com/en-us/data-center/dgx-gb200/?ncid=no-ncid))
- NVIDIA DGX B300 System (2300GB) ([info](https://www.nvidia.com/en-us/data-center/dgx-b300/?ncid=no-ncid))
- NVIDIA DGX B200 System (1440GB) ([info](https://www.nvidia.com/en-us/data-center/dgx-b200/?ncid=no-ncid))
- NVIDIA DGX H200 System (1128GB) ([info](https://www.nvidia.com/en-us/data-center/dgx-h200/?ncid=no-ncid))

### Cloud AI Machine Specs
- AWS EC2 p6: NVIDIA B200 GPU (180GB) ([info](https://aws.amazon.com/ec2/instance-types/p6/))
- AWS EC2 p5: NVIDIA H100/H200 GPU (80GB/141GB) ([info](https://aws.amazon.com/ec2/instance-types/p5/))
- AWS EC2 p4: NVIDIA A100 GPU (40GB/80GB) ([info](https://aws.amazon.com/ec2/instance-types/p4/))
- AWS EC2 g6e: NVIDIA L40S GPU (48GB) ([info](https://aws.amazon.com/ec2/instance-types/g6e/))
- AWS EC2 g6: NVIDIA L4 GPU (24GB) ([info](https://aws.amazon.com/ec2/instance-types/g6/))
- AWS EC2 g5: NVIDIA A10G GPU (24GB) ([info](https://aws.amazon.com/ec2/instance-types/g5/))
- AWS EC2 g4dn: NVIDIA T4 GPU (16GB) ([info](https://aws.amazon.com/ec2/instance-types/g4/))
- Google Cloud Compute Engine A4X: NVIDIA B200 GPU (180GB) ([info](https://cloud.google.com/compute/docs/accelerator-optimized-machines))
- Google Cloud Compute Engine A4: NVIDIA B200 GPU (180GB) ([info](https://cloud.google.com/compute/docs/accelerator-optimized-machines))
- Google Cloud Compute Engine A3: NVIDIA H100/H200 GPU (80GB/141GB) ([info](https://cloud.google.com/compute/docs/accelerator-optimized-machines))
- Google Cloud Compute Engine A2: NVIDIA A100 GPU (40GB/80GB) ([info](https://cloud.google.com/compute/docs/accelerator-optimized-machines))
- Google Cloud Compute Engine G4: NVIDIA RTX PRO 6000 Blackwell Server Edition (96GB) ([info](https://cloud.google.com/compute/docs/accelerator-optimized-machines))
- Google Cloud Compute Engine G2: NVIDIA L4 GPU (24GB) ([info](https://cloud.google.com/compute/docs/accelerator-optimized-machines))
- Google Cloud Compute Engine N1: NVIDIA T4 GPU (16GB) ([info](https://cloud.google.com/compute/docs/accelerator-optimized-machines))
- CoreWeave NVIDIA GB300 NVL72 (279GB) ([info](https://www.coreweave.com/products/nvidia-blackwell))
- CoreWeave NVIDIA GB200 NVL72 (186GB) ([info](https://www.coreweave.com/products/nvidia-blackwell))
- CoreWeave NVIDIA B200 (180GB) ([info](https://www.coreweave.com/products/nvidia-blackwell))
- CoreWeave NVIDIA HGX H200 (141GB) ([info](https://www.coreweave.com/products/hgx-h100-h200))
- CoreWeave NVIDIA HGX H100 (80GB) ([info](https://www.coreweave.com/products/hgx-h100-h200))
- CoreWeave NVIDIA GH200 (96GB) ([info](https://www.coreweave.com/products/hgx-h100-h200))
- CoreWeave NVIDIA A100 (80GB) ([info](https://www.coreweave.com/products/gpu-compute))
- CoreWeave NVIDIA RTX PRO 6000 Blackwell Server Edition (96GB) ([info](https://www.coreweave.com/products/gpu-compute))
- CoreWeave NVIDIA L40S (48GB) ([info](https://www.coreweave.com/products/gpu-compute))
- CoreWeave NVIDIA L40 (48GB) ([info](https://www.coreweave.com/products/gpu-compute))
- Nebius ([info](https://nebius.com/))
- Lambda ([info](https://lambda.ai/))
- NVIDIA DGX Cloud ([info](https://www.nvidia.com/en-us/data-center/dgx-cloud/))
- NVIDIA DGX Cloud Lepton ([info](https://www.nvidia.com/en-gb/data-center/dgx-cloud-lepton/))
- Google Colab ([info](https://colab.research.google.com/))
- Microsoft Azure Virtual Machine NDsr H100 v5
- Microsoft Azure Virtual Machine NCads H100 v5
- Microsoft Azure Virtual Machine NDm A100 v4
- Microsoft Azure Virtual Machine ND A100 v4
- Microsoft Azure Virtual Machine NC A100 v4
- Microsoft Azure Virtual Machine NC4as T4 v3

### Cloud CPU Machine Specs
- AWS EC2 m7a, m8i, m8g: General Purpose CPU ([info](https://aws.amazon.com/ec2/instance-types/m8i/))
- AWS EC2 r7a, r8i, r8g: Memory Optimized CPU ([info](https://aws.amazon.com/ec2/instance-types/r8i/))
- AWS EC2 c7a, c7i, c8g: Compute Optimized CPU ([info](https://aws.amazon.com/ec2/instance-types/c7i/))
- AWS EC2 i7i, i8g: Storage Optimized CPU ([info](https://aws.amazon.com/ec2/instance-types/i7i/))
- AWS EC2 t3, t4g: Tiny CPU ([info](https://aws.amazon.com/ec2/instance-types/t3/))
