### Setup: AI & Machine Learning Development Environment on AWS EC2
- Small scale instance: [setup_aws_gpu_single.md](setup_aws_gpu_single.md) (for inferencing, finetuning and traditional deep learning)
- Medium scale instance: [setup_aws_gpu_multi.md](setup_aws_gpu_multi.md) (For small scale models pretraining and finetuning)
- Large scale instance: [setup_aws_gpu_high.md](setup_aws_gpu_high.md) (For large language & vision models pretraining)

### Setup: LLM-based Chat AI Apps on AWS EC2
- Setup with Ubuntu 24.04 LTS: [setup_aws_simplyretrieve_2404.md](setup_aws_simplyretrieve_2404.md)
- Setup with Ubuntu 22.04 LTS: [setup_aws_simplyretrieve_2204.md](setup_aws_simplyretrieve_2204.md)

### Setup: Python Development Environment on AWS EC2
- [setup_aws_python.md](setup_aws_python.md)

### Setup: Container Development Environment on AWS EC2
- [setup_aws_docker.md](setup_aws_docker.md)

### Manual: LLM Pretraining
- [setup_info_llm_pretraining.md](setup_info_llm_pretraining.md)

### Manual: LLM Inferencing
- [setup_info_llm_inference.md](setup_info_llm_inference.md)

### Info: Useful Tools
- SSH terminal: [MobaXterm](https://mobaxterm.mobatek.net/)
- Interactive python: [Jupyter Notebook](https://jupyter.org/)
- Cloud-based interactive python and GPU: [Google Colab](https://colab.research.google.com/)

### Info: Useful Sites for Developing LLM and Chat AI
- [Hugging Face](https://huggingface.co/)
- [unsloth](https://unsloth.ai/)
- [NVIDIA NeMo](https://www.nvidia.com/en-us/ai-data-science/products/nemo/)

### Info: EC2 Instance Types and Info
- p6: NVIDIA B200 GPU (185GB)
- p5: NVIDIA H100/H200 GPU (80GB/141GB)
- p4: NVIDIA A100 GPU (40GB/80GB)
- g6e: NVIDIA L40S GPU (48GB)
- g6: NVIDIA L4 GPU (24GB)
- g5: NVIDIA A10G GPU (24GB)
- g4dn: NVIDIA T4 GPU (16GB)
- m7a, m8i, m8g: General Purpose CPU
- r7a, r8i, r8g: Memory Optimized CPU
- c7a, c7i, c8g: Compute Optimized CPU
- i7i, i8g: Storage Optimized CPU
- t3, t4g: Tiny CPU

### Info: Useful AI Machine and GPU Specs
- [setup_info_gpu.md](setup_info_gpu.md)
