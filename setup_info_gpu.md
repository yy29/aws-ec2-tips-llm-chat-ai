### Personal GPU Specs
- Ultra high cost: NVIDIA RTX PRO 6000 Blackwell (96GB)
- Very high cost: NVIDIA RTX PRO 5000 Blackwell (48GB)
- High cost: NVIDIA RTX 5090 (32GB)
- Medium cost: NVIDIA RTX PRO 4000 Blackwell (24GB)
- Low cost: NVIDIA RTX 5060 Ti (16GB)

### Personal AI Machine Specs
- NVIDIA DGX Spark (128GB) ([info](https://www.nvidia.com/en-us/products/workstations/dgx-spark/))
- NVIDIA DGX Station (288GB) ([info](https://www.nvidia.com/en-us/products/workstations/dgx-station/))

### Enterprise AI Machine Specs
- NVIDIA DGX H200 System (1128GB) ([info](https://www.nvidia.com/en-us/data-center/dgx-h200/?ncid=no-ncid))
- NVIDIA DGX B200 System (1440GB) ([info](https://www.nvidia.com/en-us/data-center/dgx-b200/?ncid=no-ncid))
- NVIDIA DGX B300 System (2300GB) ([info](https://www.nvidia.com/en-us/data-center/dgx-b300/?ncid=no-ncid))

### Rack-scale Enterprise AI System Specs
- NVIDIA DGX GB200 System ([info](https://www.nvidia.com/en-us/data-center/dgx-gb200/?ncid=no-ncid))
- NVIDIA DGX GB300 System ([info](https://www.nvidia.com/en-us/data-center/dgx-gb300/?ncid=no-ncid))

### Cloud AI Machine Specs
- AWS EC2 p6: NVIDIA B200 GPU (180GB)
- AWS EC2 p5: NVIDIA H100/H200 GPU (80GB/141GB)
- AWS EC2 p4: NVIDIA A100 GPU (40GB/80GB)
- AWS EC2 g6e: NVIDIA L40S GPU (48GB)
- AWS EC2 g6: NVIDIA L4 GPU (24GB)
- AWS EC2 g5: NVIDIA A10G GPU (24GB)
- AWS EC2 g4dn: NVIDIA T4 GPU (16GB)
- Google Cloud Compute Engine A4X: NVIDIA B200 GPU (180GB)
- Google Cloud Compute Engine A4: NVIDIA B200 GPU (180GB)
- Google Cloud Compute Engine A3: NVIDIA H100/H200 GPU (80GB/141GB)
- Google Cloud Compute Engine A2: NVIDIA A100 GPU (40GB/80GB)
- Google Cloud Compute Engine G4: NVIDIA RTX PRO 6000 Blackwell (96GB)
- Google Cloud Compute Engine G2: NVIDIA L4 GPU (24GB)
- NVIDIA DGX Cloud
